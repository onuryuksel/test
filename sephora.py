import streamlit as st
import pandas as pd
import re
import json
from bs4 import BeautifulSoup
import io

st.set_page_config(page_title="Sephora Marka Ã‡Ä±karÄ±cÄ±", layout="wide")

st.title("ğŸ’„ Sephora Marka Filtresi Veri Ã‡Ä±karÄ±cÄ±")
st.write("LÃ¼tfen Sephora Ã¼rÃ¼n listeleme sayfasÄ±nÄ±n indirilmiÅŸ HTML dosyasÄ±nÄ± yÃ¼kleyin.")
st.caption("Ã–rnek dosya: 'Makeup Essentials_ Lips, Eyes & Skin â‰¡ Sephora.html'")

def extract_brands_from_html_content(html_content):
    """
    Parses HTML content string to find embedded brand filter data within script tags,
    extracts brand names and their hit counts. Checks ALL script tags.

    Args:
        html_content (str): The HTML content as a string.

    Returns:
        tuple: A tuple containing (list of brand dictionaries, list of headers)
               or (None, None) if data extraction fails.
    """
    try:
        soup = BeautifulSoup(html_content, 'lxml')
        scripts = soup.find_all('script')
    except Exception as e:
        st.error(f"HTML ayrÄ±ÅŸtÄ±rÄ±lÄ±rken hata oluÅŸtu (lxml): {e}")
        st.info("Standart 'html.parser' ile tekrar deneniyor...")
        try:
            soup = BeautifulSoup(html_content, 'html.parser')
            scripts = soup.find_all('script')
        except Exception as e2:
            st.error(f"HTML ayrÄ±ÅŸtÄ±rÄ±lÄ±rken tekrar hata oluÅŸtu (html.parser): {e2}")
            return None, None

    brands_data = []
    found_potential_match = False # EÅŸleÅŸme olup olmadÄ±ÄŸÄ±nÄ± takip etmek iÃ§in
    fieldnames = ['Marka', 'Urun Adedi'] # CSV baÅŸlÄ±klarÄ±

    pattern = re.compile(r'"attributeId"\s*:\s*"c_brand".*?"values"\s*:\s*(\[.*?\])', re.DOTALL)

    st.write(f"Toplam {len(scripts)} script etiketi bulundu ve kontrol ediliyor...")

    for i, script in enumerate(scripts):
        script_content = script.get_text()
        if script_content:
            match = pattern.search(script_content)
            if match:
                found_potential_match = True # En az bir script'te desen bulundu
                st.info(f"Script #{i+1} iÃ§inde potansiyel 'c_brand' verisi bulundu.")
                json_like_string = match.group(1)

                # JSON string'ini temizlemeye Ã§alÄ±ÅŸalÄ±m
                json_like_string = json_like_string.strip()
                if json_like_string.endswith(','):
                   json_like_string = json_like_string[:-1]

                try:
                    data_list = json.loads(json_like_string)

                    if isinstance(data_list, list) and data_list:
                        processed_count_in_script = 0
                        for item in data_list:
                            # Veri yapÄ±sÄ±nÄ± daha dikkatli kontrol edelim
                            if (isinstance(item, dict) and
                                    'label' in item and isinstance(item['label'], str) and
                                    'hitCount' in item and isinstance(item['hitCount'], int)):
                                brands_data.append({
                                    fieldnames[0]: item['label'],
                                    fieldnames[1]: item['hitCount']
                                })
                                processed_count_in_script += 1

                        if processed_count_in_script > 0:
                           st.success(f"Script #{i+1}: {processed_count_in_script} adet geÃ§erli marka/Ã¼rÃ¼n sayÄ±sÄ± bulundu ve eklendi.")
                           # ArtÄ±k tÃ¼m geÃ§erli verileri topladÄ±ÄŸÄ±mÄ±z iÃ§in burada durabiliriz,
                           # Ã§Ã¼nkÃ¼ genellikle bu veri tek bir yerde bulunur.
                           # Ancak garanti olmasÄ± iÃ§in break koymayalÄ±m, belki baÅŸka yerde de vardÄ±r.
                           # found_data = True # EÄŸer sadece ilk bulduÄŸu yerde dursun istiyorsak bunu aÃ§Ä±p break ekleyebiliriz
                           # break
                        # else:
                           # st.warning(f"Script #{i+1}: JSON listesi ayrÄ±ÅŸtÄ±rÄ±ldÄ± ancak iÃ§inde geÃ§erli marka Ã¶ÄŸesi bulunamadÄ±.")
                    # else:
                         # st.warning(f"Script #{i+1}: Regex eÅŸleÅŸti ancak ayrÄ±ÅŸtÄ±rÄ±lan veri beklenen liste formatÄ±nda deÄŸil veya boÅŸ.")

                except json.JSONDecodeError as e:
                    st.warning(f"Script #{i+1} iÃ§inde JSON ayrÄ±ÅŸtÄ±rma hatasÄ±: {e}. Veri baÅŸlangÄ±cÄ±: {json_like_string[:100]}...")
                except Exception as e:
                    st.error(f"Script #{i+1} iÅŸlenirken beklenmedik bir hata: {e}")

    if not brands_data: # EÄŸer dÃ¶ngÃ¼ bittiÄŸinde hiÃ§ veri eklenmemiÅŸse
        if found_potential_match:
            st.error("Desenle eÅŸleÅŸen script(ler) bulundu ancak iÃ§lerinden geÃ§erli marka verisi (label/hitCount iÃ§eren liste) Ã§Ä±karÄ±lamadÄ±. Script iÃ§eriÄŸi beklenenden farklÄ± olabilir.")
        else:
            st.error("HTML iÃ§inde 'c_brand' attributeId'sine sahip marka filtresi deseni iÃ§eren hiÃ§bir script etiketi bulunamadÄ±.")
        return None, None

    # Yinelenenleri (eÄŸer varsa) kaldÄ±r
    unique_brands_data = []
    seen_brands = set()
    for brand_entry in brands_data:
        if brand_entry['Marka'] not in seen_brands:
            unique_brands_data.append(brand_entry)
            seen_brands.add(brand_entry['Marka'])

    st.info(f"Toplam {len(unique_brands_data)} benzersiz marka bulundu.")
    return unique_brands_data, fieldnames

# --- Streamlit File Uploader ---
uploaded_file = st.file_uploader("HTML DosyasÄ±nÄ± Buraya SÃ¼rÃ¼kleyin veya SeÃ§in", type=["html", "htm"])

if uploaded_file is not None:
    try:
        stringio = io.StringIO(uploaded_file.getvalue().decode("utf-8"))
        html_content = stringio.read()
        st.success(f"'{uploaded_file.name}' baÅŸarÄ±yla yÃ¼klendi ve okundu.")

        with st.spinner("Marka verileri Ã§Ä±karÄ±lÄ±yor..."):
            brands_data, headers = extract_brands_from_html_content(html_content)

        if brands_data and headers:
            st.success("Marka verileri baÅŸarÄ±yla Ã§Ä±karÄ±ldÄ±!")
            df = pd.DataFrame(brands_data)
            st.dataframe(df, use_container_width=True)
            csv_string = df.to_csv(index=False, encoding='utf-8-sig')
            st.download_button(
               label="CSV Olarak Ä°ndir",
               data=csv_string,
               file_name='sephora_markalar.csv',
               mime='text/csv',
            )
        # Hata mesajlarÄ± artÄ±k fonksiyon iÃ§inde veriliyor.

    except UnicodeDecodeError:
        st.error("Dosya kodlamasÄ± UTF-8 deÄŸil gibi gÃ¶rÃ¼nÃ¼yor. LÃ¼tfen UTF-8 formatÄ±nda kaydedilmiÅŸ bir HTML dosyasÄ± yÃ¼kleyin.")
    except Exception as e:
        st.error(f"Dosya iÅŸlenirken genel bir hata oluÅŸtu: {e}")
        st.exception(e)
