import streamlit as st
# requests kÃ¼tÃ¼phanesine artÄ±k gerek yok
from bs4 import BeautifulSoup
import pandas as pd
import re
import json
from io import StringIO
import os # Dosya adÄ± iÅŸlemleri iÃ§in

# Sayfa BaÅŸlÄ±ÄŸÄ±
st.set_page_config(page_title="Sephora Marka Filtre Ã‡ekici", layout="wide")
st.title("ğŸ’„ Sephora Marka Filtre Veri Ã‡ekici (HTML YÃ¼kleme)")
st.caption("KaydettiÄŸiniz Sephora Ã¼rÃ¼n listeleme sayfasÄ± HTML dosyasÄ±nÄ± yÃ¼kleyerek marka filtresindeki verileri CSV olarak indirin.")

# --- KullanÄ±cÄ± TalimatlarÄ± ---
st.info("""
**NasÄ±l KullanÄ±lÄ±r:**
1.  Marka filtrelerini Ã§ekmek istediÄŸiniz Sephora Ã¼rÃ¼n listeleme sayfasÄ±nÄ± (Ã¶rn: Makyaj, ParfÃ¼m kategorisi) **web tarayÄ±cÄ±nÄ±zda** aÃ§Ä±n.
2.  SayfanÄ±n **tamamen** yÃ¼klendiÄŸinden emin olun (tÃ¼m Ã¼rÃ¼nler ve filtreler gÃ¶rÃ¼nÃ¼r olmalÄ±).
3.  TarayÄ±cÄ±da sayfaya saÄŸ tÄ±klayÄ±n ve **"FarklÄ± Kaydet" (Save Page As...)** seÃ§eneÄŸini seÃ§in.
4.  KayÄ±t tÃ¼rÃ¼ olarak **"Web SayfasÄ±, Sadece HTML" (Webpage, HTML Only)** veya benzeri bir seÃ§eneÄŸi seÃ§in (TÃ¼m sayfayÄ± deÄŸil, sadece HTML'i kaydettiÄŸinizden emin olun). Dosya uzantÄ±sÄ± `.html` veya `.htm` olmalÄ±dÄ±r.
5.  KaydettiÄŸiniz bu `.html` dosyasÄ±nÄ± aÅŸaÄŸÄ±daki "GÃ¶zat" dÃ¼ÄŸmesini kullanarak yÃ¼kleyin.
""")

# --- Fonksiyonlar (Ã–ncekiyle BÃ¼yÃ¼k Ã–lÃ§Ã¼de AynÄ±, fetch_* fonksiyonlarÄ± kaldÄ±rÄ±ldÄ±) ---

def find_brand_filter(data):
    """Recursive olarak JSON/dictionary iÃ§inde 'attributeId': 'c_brand' arar."""
    if isinstance(data, dict):
        if data.get('attributeId') == 'c_brand' and 'values' in data:
            if data.get('values') and isinstance(data['values'], list) and all(isinstance(item, dict) for item in data['values']):
                 return data
        # 'image' gibi bÃ¼yÃ¼k/gereksiz alanlarÄ± atla (performans)
        for key, value in data.items():
            if key not in ['image', 'images', 'icon', 'icons', 'banner', 'banners', 'variations', 'attributes', 'promotions']:
                result = find_brand_filter(value)
                if result:
                    return result
    elif isinstance(data, list):
        # Ã‡ok uzun listelerde aramayÄ± sÄ±nÄ±rlayabiliriz (opsiyonel)
        # items_to_check = data[:1000] if len(data) > 1000 else data
        items_to_check = data
        for item in items_to_check:
            result = find_brand_filter(item)
            if result:
                return result
    return None

def extract_brands_directly(soup):
    """Alternatif yÃ¶ntem: DoÄŸrudan HTML elementlerini parse etmeye Ã§alÄ±ÅŸÄ±r."""
    st.info("Alternatif yÃ¶ntem (HTML elementleri) deneniyor...")
    brands_data = []
    extracted_brands = set()
    try:
        # 'Brands' baÅŸlÄ±ÄŸÄ±nÄ± veya filtre bÃ¶lÃ¼mÃ¼nÃ¼ bul
        # Daha genel class isimleri veya yapÄ±sal ipuÃ§larÄ± ara
        brand_section = None
        possible_headers = soup.find_all(['h3', 'h2', 'button', 'div'], string=re.compile(r'Brands?', re.IGNORECASE))
        for header in possible_headers:
            # BaÅŸlÄ±ÄŸÄ±n parent'larÄ±nÄ± kontrol et, filtre elemanlarÄ± iÃ§eriyor mu?
            current = header
            for _ in range(5): # 5 seviye yukarÄ± bak
                parent = current.find_parent(['div', 'section', 'aside'], class_=re.compile(r'filter|facet|refine', re.IGNORECASE))
                if parent and parent.find(['input', 'label'], class_=re.compile(r'checkbox|facet-value', re.IGNORECASE)):
                     brand_section = parent
                     st.info(f"BaÅŸlÄ±ktan potansiyel filtre bÃ¶lÃ¼mÃ¼ bulundu: <{brand_section.name} class='{brand_section.get('class', [])}'>")
                     break
                if not parent: break
                current = parent
            if brand_section: break # Ä°lk bulduÄŸumuzla devam et

        if not brand_section:
            st.warning("Marka baÅŸlÄ±ÄŸÄ±ndan filtre bÃ¶lÃ¼mÃ¼ bulunamadÄ±. Genel container aramasÄ± yapÄ±lÄ±yor...")
            possible_sections = soup.find_all('div', class_=re.compile(r'filter|facet|refine', re.IGNORECASE))
            for section in possible_sections:
                 # Ä°Ã§inde 'brand' kelimesi geÃ§en input veya Ã§ok sayÄ±da potansiyel filtre deÄŸeri var mÄ±?
                 if section.find('input', attrs={'name': re.compile(r'brand', re.IGNORECASE)}) or \
                    len(section.find_all(['label', 'li', 'div'], class_=re.compile(r'checkbox|facet-value|option', re.IGNORECASE))) > 3:
                    brand_section = section
                    st.info(f"Genel aramada potansiyel filtre bÃ¶lÃ¼mÃ¼ bulundu: <{brand_section.name} class='{brand_section.get('class', [])}'>")
                    break

        if not brand_section:
            st.error("Marka filtresi bÃ¶lÃ¼mÃ¼ HTML iÃ§inde bulunamadÄ± (Alternatif YÃ¶ntem).")
            return None

        # Marka item'larÄ±nÄ± veya label'larÄ±nÄ± bul (daha geniÅŸ class aramasÄ±)
        brand_items = brand_section.find_all(['div', 'li', 'label'], class_=re.compile(r'checkbox|facet-value|filter-value|facet-label|option', re.IGNORECASE))

        if not brand_items:
             # Sadece input'larÄ± bulup parent'larÄ±ndan text almayÄ± dene
             inputs = brand_section.find_all('input', type='checkbox', attrs={'name': re.compile(r'brand', re.IGNORECASE)})
             brand_items = [inp.find_parent('label') or inp.find_parent('div') for inp in inputs] # Parent label veya div ara
             brand_items = [item for item in brand_items if item] # None olanlarÄ± kaldÄ±r

        if not brand_items:
            st.error("Marka listesi elementleri (item/label/input parent) bulunamadÄ±.")
            return None

        st.info(f"Bulunan olasÄ± marka elementi sayÄ±sÄ±: {len(brand_items)}")

        for item in brand_items:
            text_content = item.get_text(separator=' ', strip=True)
            # Regex: BaÅŸÄ±nda potansiyel ikon/boÅŸluk olabilecek Marka AdÄ± (SayÄ±) veya Marka AdÄ± SayÄ±
            match = re.search(r'^(?:[\W\s]*)?([a-zA-Z0-9 &\'\+.-]+?)\s*\(?(\d+)\)?$', text_content)
            if match:
                brand_name = match.group(1).strip()
                count = int(match.group(2))
                if brand_name.lower() not in ['no', 'yes', ''] and brand_name not in extracted_brands:
                    brands_data.append({'Marka': brand_name,'ÃœrÃ¼n SayÄ±sÄ±': count})
                    extracted_brands.add(brand_name)

        if brands_data:
            st.success(f"{len(brands_data)} marka verisi doÄŸrudan HTML'den baÅŸarÄ±yla Ã§ekildi (Alternatif YÃ¶ntem).")
            return pd.DataFrame(brands_data)
        else:
            st.warning("DoÄŸrudan HTML taramasÄ±nda yapÄ±sal marka verisi bulunamadÄ± veya ayÄ±klanamadÄ±.")
            return None

    except Exception as e:
        st.error(f"MarkalarÄ± doÄŸrudan HTML'den Ã§ekerken hata oluÅŸtu (Alternatif YÃ¶ntem): {e}")
        return None


def extract_brands_from_html(html_content):
    """HTML iÃ§eriÄŸinden marka verilerini Ã§Ä±karÄ±r (__NEXT_DATA__ Ã¶ncelikli)."""
    if not html_content:
        st.error("HTML iÃ§eriÄŸi boÅŸ veya okunamadÄ±.")
        return None

    soup = BeautifulSoup(html_content, 'lxml')
    brands_data = []
    processed_brands = set() # Yinelenenleri Ã¶nlemek iÃ§in

    # 1. __NEXT_DATA__ script'ini bul ve iÅŸle
    script_tag = soup.find('script', id='__NEXT_DATA__')
    if script_tag:
        st.info("__NEXT_DATA__ script'i bulundu, JSON verisi iÅŸleniyor...")
        try:
            next_data = json.loads(script_tag.string)
            brand_filter = find_brand_filter(next_data) # Recursive arama

            if brand_filter and 'values' in brand_filter and isinstance(brand_filter['values'], list):
                for item in brand_filter['values']:
                    if isinstance(item, dict) and 'label' in item and 'hitCount' in item:
                         brand_name = item['label'].strip()
                         # 'No' ve boÅŸ etiketleri ve tekrarlarÄ± atla
                         if brand_name and brand_name.lower() != 'no' and brand_name not in processed_brands:
                            brands_data.append({
                                'Marka': brand_name,
                                'ÃœrÃ¼n SayÄ±sÄ±': item.get('hitCount', 0) # hitCount yoksa 0
                            })
                            processed_brands.add(brand_name)

                if brands_data:
                     st.success(f"{len(brands_data)} marka verisi __NEXT_DATA__ iÃ§inden baÅŸarÄ±yla Ã§ekildi.")
                     return pd.DataFrame(brands_data)
                else:
                     st.warning("__NEXT_DATA__ iÃ§inde marka filtresi ('c_brand') bulundu ancak geÃ§erli marka/sayÄ± Ã§ifti yoktu. Alternatif yÃ¶ntem deneniyor...")
            else:
                st.warning("__NEXT_DATA__ iÃ§inde 'c_brand' filtresi bulunamadÄ±. Alternatif yÃ¶ntem deneniyor...")
        except Exception as e:
            st.error(f"__NEXT_DATA__ iÅŸlenirken hata: {e}. Alternatif yÃ¶ntem deneniyor...")
    else:
        st.warning("__NEXT_DATA__ script'i bulunamadÄ±. Alternatif yÃ¶ntem (doÄŸrudan HTML tarama) deneniyor...")

    # 2. Alternatif YÃ¶ntem: DoÄŸrudan HTML'den Ã§ekmeyi dene
    return extract_brands_directly(soup)


# --- Streamlit ArayÃ¼zÃ¼ ---
uploaded_file = st.file_uploader(
    "KaydedilmiÅŸ Sephora HTML DosyasÄ±nÄ± YÃ¼kleyin (.html/.htm)",
    type=["html", "htm"],
    accept_multiple_files=False
)

if uploaded_file is not None:
    st.success(f"'{uploaded_file.name}' baÅŸarÄ±yla yÃ¼klendi.")
    with st.spinner("HTML dosyasÄ± okunuyor ve markalar ayrÄ±ÅŸtÄ±rÄ±lÄ±yor..."):
        try:
            # Dosya iÃ§eriÄŸini oku ve decode et
            html_content = uploaded_file.getvalue().decode("utf-8")
            st.info("HTML iÃ§eriÄŸi okundu.")

            # MarkalarÄ± Ã§Ä±kar
            df_brands = extract_brands_from_html(html_content)

            if df_brands is not None and not df_brands.empty:
                st.subheader("Ã‡ekilen Marka Verileri")
                # DataFrame'i gÃ¶sterirken indeksi gizle
                st.dataframe(df_brands.set_index('Marka'), use_container_width=True)

                # --- CSV Ä°ndirme ---
                try:
                    csv_buffer = StringIO()
                    df_brands.to_csv(csv_buffer, index=False, encoding='utf-8') # UTF-8 iyidir
                    csv_data = csv_buffer.getvalue()

                    # YÃ¼klenen dosya adÄ±ndan CSV adÄ± tÃ¼ret
                    base_filename = os.path.splitext(uploaded_file.name)[0]
                    csv_filename = f"sephora_markalar_{base_filename}.csv"

                    st.download_button(
                        label="ğŸ’¾ CSV Olarak Ä°ndir",
                        data=csv_data,
                        file_name=csv_filename,
                        mime='text/csv',
                    )
                except Exception as e:
                    st.error(f"CSV oluÅŸturulurken veya indirme butonu hazÄ±rlanÄ±rken hata: {e}")

            elif df_brands is not None: # BoÅŸ DataFrame dÃ¶ndÃ¼
                 st.warning("YÃ¼klenen HTML dosyasÄ±nda marka filtresi verisi bulunamadÄ± veya ayÄ±klanamadÄ±. LÃ¼tfen HTML'i 'Sadece HTML' olarak doÄŸru kaydettiÄŸinizden ve sayfanÄ±n tam yÃ¼klendiÄŸinden emin olun.")
            # else: extract_brands_from_html iÃ§inde zaten hata mesajÄ± verildi.

        except UnicodeDecodeError:
            st.error("Dosya UTF-8 formatÄ±nda okunamadÄ±. LÃ¼tfen dosyayÄ± tarayÄ±cÄ±dan 'FarklÄ± Kaydet -> Web SayfasÄ±, Sadece HTML' seÃ§eneÄŸi ile tekrar kaydedip deneyin.")
        except Exception as e:
            st.error(f"Dosya iÅŸlenirken beklenmedik bir hata oluÅŸtu: {e}")

st.markdown("---")
st.caption("Not: Bu uygulama, yÃ¼klediÄŸiniz HTML dosyasÄ±nÄ±n iÃ§indeki verilere dayanÄ±r. En iyi sonuÃ§ iÃ§in sayfayÄ± tarayÄ±cÄ±da 'FarklÄ± Kaydet -> Web SayfasÄ±, Sadece HTML' olarak kaydedin.")
