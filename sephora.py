import streamlit as st
from bs4 import BeautifulSoup
import pandas as pd
import re
import json
from io import StringIO
import os

# Sayfa BaÅŸlÄ±ÄŸÄ± ve Talimatlar (AynÄ±)
st.set_page_config(page_title="Sephora Marka Filtre Ã‡ekici", layout="wide")
st.title("ğŸ’„ Sephora Marka Filtre Veri Ã‡ekici (HTML YÃ¼kleme)2")
st.caption("KaydettiÄŸiniz Sephora Ã¼rÃ¼n listeleme sayfasÄ± HTML dosyasÄ±nÄ± yÃ¼kleyerek marka filtresindeki verileri CSV olarak indirin.")
st.info("""
**NasÄ±l KullanÄ±lÄ±r:**
1.  Marka filtrelerini Ã§ekmek istediÄŸiniz Sephora Ã¼rÃ¼n listeleme sayfasÄ±nÄ± (Ã¶rn: Makyaj, ParfÃ¼m kategorisi) **web tarayÄ±cÄ±nÄ±zda** aÃ§Ä±n.
2.  SayfanÄ±n **tamamen** yÃ¼klendiÄŸinden emin olun (sol taraftaki **"Refine"** veya benzeri bÃ¶lÃ¼mdeki **"Brands"** filtresinin ve markalarÄ±n gÃ¶rÃ¼nÃ¼r olduÄŸundan emin olun).
3.  TarayÄ±cÄ±da sayfaya saÄŸ tÄ±klayÄ±n ve **"FarklÄ± Kaydet" (Save Page As...)** seÃ§eneÄŸini seÃ§in.
4.  KayÄ±t tÃ¼rÃ¼ olarak **"Web SayfasÄ±, Sadece HTML" (Webpage, HTML Only)** seÃ§eneÄŸini seÃ§in. Dosya uzantÄ±sÄ± `.html` veya `.htm` olmalÄ±dÄ±r.
5.  KaydettiÄŸiniz bu `.html` dosyasÄ±nÄ± aÅŸaÄŸÄ±daki "GÃ¶zat" dÃ¼ÄŸmesini kullanarak yÃ¼kleyin.
""")

# --- Fonksiyonlar ---

def find_nested_data(data, target_key, target_value):
    """Ä°Ã§ iÃ§e geÃ§miÅŸ dict/list'lerde belirli bir anahtar-deÄŸer Ã§iftini arar."""
    if isinstance(data, dict):
        if data.get(target_key) == target_value:
            return data
        for key, value in data.items():
            # Basit performans iyileÅŸtirmesi: Ã‡ok bÃ¼yÃ¼k listeleri/sÃ¶zlÃ¼kleri atla
            if isinstance(value, (dict, list)) and len(str(value)) > 5000: # Boyut eÅŸiÄŸi ayarlanabilir
                 continue
            found = find_nested_data(value, target_key, target_value)
            if found: return found
    elif isinstance(data, list):
        # Ã‡ok uzun listelerde aramayÄ± sÄ±nÄ±rlama (opsiyonel)
        items_to_check = data #[:500] if len(data) > 500 else data
        for item in items_to_check:
            found = find_nested_data(item, target_key, target_value)
            if found: return found
    return None

def extract_brands_from_next_data(soup):
    """__NEXT_DATA__ script'inden marka verilerini Ã§Ä±karÄ±r (Daha saÄŸlam iÃ§erik alma)."""
    brands_data = []
    processed_brands = set()
    script_tag = soup.find('script', id='__NEXT_DATA__')

    if not script_tag:
        st.warning("__NEXT_DATA__ script etiketi HTML iÃ§inde bulunamadÄ±.")
        return None

    st.info("__NEXT_DATA__ script etiketi bulundu.")

    # Ä°Ã§eriÄŸi almayÄ± dene (Ã¶nce .string, olmazsa .get_text())
    script_content = None
    if script_tag.string:
        script_content = script_tag.string.strip()
        st.info(".string ile iÃ§erik alÄ±ndÄ±.")
    else:
        st.warning(".string ile iÃ§erik alÄ±namadÄ± (None), .get_text() deneniyor...")
        script_content = script_tag.get_text(strip=True)
        if script_content:
             st.info(".get_text() ile iÃ§erik alÄ±ndÄ±.")
        else:
             st.error("__NEXT_DATA__ etiketi bulundu ancak ne .string ne de .get_text() ile iÃ§erik alÄ±namadÄ±.")
             return None


    if not script_content:
        st.error("__NEXT_DATA__ etiketi bulundu ancak iÃ§eriÄŸi boÅŸ.")
        return None

    st.info(f"__NEXT_DATA__ iÃ§eriÄŸinin baÅŸÄ± (ilk 500 karakter):\n```json\n{script_content[:500]}...\n```")

    # JSON ayrÄ±ÅŸtÄ±rmayÄ± dene
    try:
        # Bazen baÅŸta/sonda gereksiz karakterler olabilir, JSON nesnesinin baÅŸladÄ±ÄŸÄ± yerden almayÄ± dene
        json_start_index = script_content.find('{')
        json_end_index = script_content.rfind('}') + 1
        if json_start_index != -1 and json_end_index != 0:
            potential_json = script_content[json_start_index:json_end_index]
            next_data = json.loads(potential_json)
            st.success("__NEXT_DATA__ iÃ§eriÄŸi JSON olarak baÅŸarÄ±yla ayrÄ±ÅŸtÄ±rÄ±ldÄ±.")
        else:
            st.error("__NEXT_DATA__ iÃ§eriÄŸinde geÃ§erli JSON baÅŸlangÄ±cÄ±/bitiÅŸi bulunamadÄ±.")
            return None

        # 'attributeId': 'c_brand' iÃ§eren yapÄ±yÄ± bul
        brand_filter_dict = find_nested_data(next_data, 'attributeId', 'c_brand')

        if brand_filter_dict:
            st.success("'c_brand' attributeId iÃ§eren yapÄ± bulundu.")
            if 'values' in brand_filter_dict and isinstance(brand_filter_dict['values'], list):
                st.info(f"Marka 'values' listesinde {len(brand_filter_dict['values'])} Ã¶ÄŸe bulundu.")
                for item in brand_filter_dict['values']:
                    if isinstance(item, dict) and 'label' in item and 'hitCount' in item:
                        brand_name = item['label'].strip()
                        hit_count = item['hitCount']
                        if brand_name and isinstance(hit_count, int) and brand_name.lower() != 'no' and brand_name not in processed_brands:
                            brands_data.append({'Marka': brand_name, 'ÃœrÃ¼n SayÄ±sÄ±': hit_count})
                            processed_brands.add(brand_name)
                if brands_data:
                    st.info(f"{len(brands_data)} geÃ§erli marka/sayÄ± Ã§ifti __NEXT_DATA__ iÃ§inden ayÄ±klandÄ±.")
                    return pd.DataFrame(brands_data)
                else:
                    st.warning("Marka filtresi ('c_brand') bulundu ancak iÃ§inde geÃ§erli Ã¶ÄŸe bulunamadÄ±.")
                    return pd.DataFrame()
            else:
                st.warning("'c_brand' yapÄ±sÄ± bulundu ancak geÃ§erli 'values' listesi yok.")
                return None
        else:
            st.warning("__NEXT_DATA__ iÃ§inde 'c_brand' yapÄ±sÄ± bulunamadÄ±.")
            return None

    except json.JSONDecodeError as e:
        st.error(f"__NEXT_DATA__ iÃ§eriÄŸi JSON olarak ayrÄ±ÅŸtÄ±rÄ±lamadÄ±: {e}")
        st.error("HatanÄ±n oluÅŸtuÄŸu yerdeki iÃ§erik (ilk 100 karakter): " + repr(script_content[:100]))
        return None
    except Exception as e:
        st.error(f"__NEXT_DATA__ iÅŸlenirken beklenmedik hata: {e}")
        return None


def extract_brands_directly(soup):
    """Alternatif yÃ¶ntem: DoÄŸrudan HTML elementlerini parse etmeye Ã§alÄ±ÅŸÄ±r."""
    # Bu fonksiyon ÅŸimdilik aynÄ± kalabilir, __NEXT_DATA__'nÄ±n Ã§alÄ±ÅŸmasÄ± Ã¶ncelikli.
    st.info("Alternatif yÃ¶ntem (doÄŸrudan HTML elementleri) deneniyor...")
    # ... (Ã¶nceki kodla aynÄ±) ...
    brands_data = []
    processed_brands = set()
    try:
        brand_section = None
        css_selectors = [
            'div[data-testid="facet-container-Brands"]',
            'div[data-testid="Brands"]',
            'div[aria-labelledby*="brand"]',
            'section[aria-labelledby*="brand"]',
            'aside[aria-labelledby*="brand"]'
        ]
        for selector in css_selectors:
            found_section = soup.select_one(selector)
            if found_section:
                brand_section = found_section
                st.info(f"Potansiyel filtre bÃ¶lÃ¼mÃ¼ CSS seÃ§ici ile bulundu: '{selector}'")
                break

        if not brand_section:
            st.warning("CSS seÃ§icileri ile filtre bÃ¶lÃ¼mÃ¼ bulunamadÄ±, metin aramasÄ± yapÄ±lÄ±yor...")
            possible_headers = soup.find_all(['h3', 'h2', 'button', 'div'], string=re.compile(r'^\s*Brands?\s*$', re.IGNORECASE))
            for header in possible_headers:
                current = header
                for _ in range(5):
                    parent = current.find_parent(['div', 'section', 'aside'])
                    if parent and (parent.find('input', type='checkbox') or len(parent.find_all('li')) > 2):
                        brand_section = parent
                        st.info(f"'Brands' baÅŸlÄ±ÄŸÄ±ndan yola Ã§Ä±karak parent bulundu: <{brand_section.name} class='{brand_section.get('class', 'N/A')}' id='{brand_section.get('id', 'N/A')}'>")
                        break
                    if not parent: break
                    current = parent
                if brand_section: break

        if not brand_section:
            st.error("Marka filtresi bÃ¶lÃ¼mÃ¼ HTML iÃ§inde otomatik olarak tespit edilemedi (Alternatif YÃ¶ntem).")
            return None

        items = brand_section.find_all('label', class_=re.compile(r'checkbox|facet', re.IGNORECASE))
        if not items:
            inputs = brand_section.find_all('input', type='checkbox')
            items = [inp.find_parent(['label','div','li']) for inp in inputs if inp.find_parent(['label','div','li'])]
        if not items:
             items = brand_section.find_all(['li','div'], text=re.compile(r'\(\d+\)\s*$'))

        if not items:
            st.error("Marka listesi elementleri bulunamadÄ±.")
            return None

        st.info(f"Bulunan olasÄ± marka elementi sayÄ±sÄ±: {len(items)}")

        for item in items:
            text_content = item.get_text(separator=' ', strip=True)
            match = re.search(r'([a-zA-Z0-9 &\'\+\.-]+)\s*\((\d+)\)', text_content)
            if match:
                brand_name = match.group(1).strip()
                count = int(match.group(2))
                if brand_name and brand_name.lower() not in ['no', 'yes'] and brand_name not in processed_brands:
                    brands_data.append({'Marka': brand_name, 'ÃœrÃ¼n SayÄ±sÄ±': count})
                    processed_brands.add(brand_name)

        if brands_data:
            st.success(f"{len(brands_data)} marka verisi doÄŸrudan HTML'den baÅŸarÄ±yla Ã§ekildi.")
            return pd.DataFrame(brands_data)
        else:
            st.warning("DoÄŸrudan HTML taramasÄ±nda yapÄ±sal marka verisi bulunamadÄ± veya ayÄ±klanamadÄ±.")
            return None

    except Exception as e:
        st.error(f"MarkalarÄ± doÄŸrudan HTML'den Ã§ekerken hata oluÅŸtu (Alternatif YÃ¶ntem): {e}")
        return None


# --- Streamlit ArayÃ¼zÃ¼ (Ana iÅŸleyiÅŸ aynÄ±) ---
uploaded_file = st.file_uploader(
    "KaydedilmiÅŸ Sephora HTML DosyasÄ±nÄ± YÃ¼kleyin (.html/.htm)",
    type=["html", "htm"],
    accept_multiple_files=False
)

if uploaded_file is not None:
    st.success(f"'{uploaded_file.name}' baÅŸarÄ±yla yÃ¼klendi.")
    with st.spinner("HTML dosyasÄ± okunuyor ve markalar ayrÄ±ÅŸtÄ±rÄ±lÄ±yor..."):
        df_brands = None
        html_content = None
        try:
            html_content_bytes = uploaded_file.getvalue()
            try:
                html_content = html_content_bytes.decode("utf-8")
            except UnicodeDecodeError:
                st.warning("UTF-8 ile decode edilemedi, latin-1 deneniyor...")
                html_content = html_content_bytes.decode("latin-1")
            st.info("HTML iÃ§eriÄŸi okundu.")
        except Exception as e:
             st.error(f"Dosya okunurken/decode edilirken hata oluÅŸtu: {e}")

        if html_content:
            try:
                 soup = BeautifulSoup(html_content, 'lxml')
                 st.info("HTML, BeautifulSoup ile baÅŸarÄ±yla parse edildi.")

                 # Ã–nce __NEXT_DATA__ dene
                 df_brands = extract_brands_from_next_data(soup) # GÃ¼ncellenmiÅŸ fonksiyonu Ã§aÄŸÄ±r

                 # BaÅŸarÄ±sÄ±z olursa veya boÅŸ dÃ¶nerse alternatif yÃ¶ntemi dene
                 if df_brands is None or df_brands.empty:
                      if df_brands is None:
                           st.info("__NEXT_DATA__ bulunamadÄ± veya iÅŸlenemedi, doÄŸrudan HTML deneniyor.")
                      else:
                           st.info("__NEXT_DATA__ iÅŸlendi ancak veri bulunamadÄ±, doÄŸrudan HTML deneniyor.")
                      try:
                          df_brands = extract_brands_directly(soup) # Alternatif yÃ¶ntem
                      except Exception as e:
                          st.error(f"Alternatif HTML ayrÄ±ÅŸtÄ±rma yÃ¶nteminde hata oluÅŸtu: {e}")
                          df_brands = None

                 # Sonucu gÃ¶ster ve CSV indir
                 if df_brands is not None and not df_brands.empty:
                     st.subheader("Ã‡ekilen Marka Verileri")
                     st.dataframe(df_brands.set_index('Marka'), use_container_width=True)
                     # --- CSV Ä°ndirme ---
                     try:
                         csv_buffer = StringIO()
                         df_brands.to_csv(csv_buffer, index=False, encoding='utf-8')
                         csv_data = csv_buffer.getvalue()
                         base_filename = os.path.splitext(uploaded_file.name)[0]
                         csv_filename = f"sephora_markalar_{base_filename}.csv"
                         st.download_button(
                             label="ğŸ’¾ CSV Olarak Ä°ndir",
                             data=csv_data,
                             file_name=csv_filename,
                             mime='text/csv',
                         )
                     except Exception as e:
                         st.error(f"CSV oluÅŸturulurken/indirilirken hata: {e}")
                 elif df_brands is not None: # BoÅŸ DataFrame geldiyse
                      st.warning("YÃ¼klenen HTML dosyasÄ±nda, denenen yÃ¶ntemlerle marka filtresi verisi bulunamadÄ±.")
                 # else: df_brands = None ise hata zaten yukarÄ±da verildi.

            except Exception as e:
                st.error(f"HTML iÃ§eriÄŸi BeautifulSoup ile parse edilirken hata oluÅŸtu: {e}")

st.markdown("---")
st.caption("Not: Bu uygulama, yÃ¼klediÄŸiniz HTML dosyasÄ±nÄ±n iÃ§indeki verilere dayanÄ±r. En iyi sonuÃ§ iÃ§in sayfayÄ± tarayÄ±cÄ±da **tamamen yÃ¼klendikten sonra** 'FarklÄ± Kaydet -> Web SayfasÄ±, Sadece HTML' olarak kaydedin.")
