import streamlit as st
import requests
from bs4 import BeautifulSoup
import pandas as pd
import re
import json
from io import StringIO  # CSV indirme iÃ§in gerekli

# Sayfa BaÅŸlÄ±ÄŸÄ±
st.set_page_config(page_title="Sephora Marka Filtre Ã‡ekici", layout="wide")
st.title("ğŸ’„ Sephora Marka Filtre Veri Ã‡ekici")
st.caption("Sephora Ã¼rÃ¼n listeleme sayfasÄ± linkini girerek marka filtresindeki verileri CSV olarak indirin.")

# --- Fonksiyonlar ---
def fetch_html(url):
    """Verilen URL'den HTML iÃ§eriÄŸini Ã§eker."""
    headers = {
        'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/91.0.4472.124 Safari/537.36'
    }
    try:
        response = requests.get(url, headers=headers, timeout=15)
        response.raise_for_status()  # HTTP hatalarÄ±nÄ± kontrol et (4xx veya 5xx)
        return response.text
    except requests.exceptions.Timeout:
        st.error(f"Ä°stek zaman aÅŸÄ±mÄ±na uÄŸradÄ±: {url}")
        return None
    except requests.exceptions.RequestException as e:
        st.error(f"URL alÄ±nÄ±rken hata oluÅŸtu: {e}")
        return None

def extract_brands_from_html(html_content):
    """
    HTML iÃ§eriÄŸinden __NEXT_DATA__ script'ini bularak marka verilerini Ã§Ä±karÄ±r.
    Sephora'nÄ±n Next.js kullandÄ±ÄŸÄ± ve veriyi script tag'ine gÃ¶mdÃ¼ÄŸÃ¼ varsayÄ±lÄ±r.
    """
    if not html_content:
        return None

    soup = BeautifulSoup(html_content, 'lxml') # lxml parser kullanÄ±yoruz
    brands_data = []

    # Next.js'in veri gÃ¶mdÃ¼ÄŸÃ¼ script tag'ini bul
    script_tag = soup.find('script', id='__NEXT_DATA__')

    if not script_tag:
        st.warning("Sayfa yapÄ±sÄ± beklenenden farklÄ±. __NEXT_DATA__ script'i bulunamadÄ±. Alternatif yÃ¶ntem deneniyor...")
        # Alternatif YÃ¶ntem: HTML iÃ§indeki filter yapÄ±sÄ±nÄ± arama (daha az gÃ¼venilir)
        return extract_brands_directly(soup)


    try:
        # Script iÃ§eriÄŸini JSON olarak parse et
        next_data = json.loads(script_tag.string)
        # Veri yapÄ±sÄ± deÄŸiÅŸebilir, doÄŸru yolu bulmak iÃ§in inspect gerekebilir.
        # Ã–rnek yapÄ±da props.pageProps.initialState... gibi bir yol izlenebilir.
        # Burada daha genel bir arama yapÄ±yoruz.

        # Ã‡ok katmanlÄ± JSON iÃ§inde 'attributeId': 'c_brand' iÃ§eren objeyi bul
        brand_filter = find_brand_filter(next_data)

        if brand_filter and 'values' in brand_filter:
            for item in brand_filter['values']:
                if 'label' in item and 'hitCount' in item and item['label'] and item['hitCount'] is not None:
                    brands_data.append({
                        'Marka': item['label'],
                        'ÃœrÃ¼n SayÄ±sÄ±': item['hitCount']
                    })
            st.success(f"{len(brands_data)} marka verisi __NEXT_DATA__ iÃ§inden baÅŸarÄ±yla Ã§ekildi.")
            return pd.DataFrame(brands_data)
        else:
            st.warning("__NEXT_DATA__ iÃ§inde marka filtresi bulunamadÄ±. Alternatif yÃ¶ntem deneniyor...")
            return extract_brands_directly(soup)

    except (json.JSONDecodeError, KeyError, TypeError) as e:
        st.error(f"__NEXT_DATA__ parse edilirken hata: {e}. Alternatif yÃ¶ntem deneniyor...")
        return extract_brands_directly(soup)
    except Exception as e:
         st.error(f"MarkalarÄ± Ã§ekerken beklenmedik bir hata oluÅŸtu: {e}. Alternatif yÃ¶ntem deneniyor...")
         return extract_brands_directly(soup)

def find_brand_filter(data):
    """Recursive olarak JSON/dictionary iÃ§inde 'attributeId': 'c_brand' arar."""
    if isinstance(data, dict):
        if data.get('attributeId') == 'c_brand' and 'values' in data:
            return data
        for key, value in data.items():
            result = find_brand_filter(value)
            if result:
                return result
    elif isinstance(data, list):
        for item in data:
            result = find_brand_filter(item)
            if result:
                return result
    return None


def extract_brands_directly(soup):
    """
    Alternatif yÃ¶ntem: DoÄŸrudan HTML elementlerini parse etmeye Ã§alÄ±ÅŸÄ±r.
    Bu yÃ¶ntem sayfa yapÄ±sÄ± deÄŸiÅŸirse kolayca bozulabilir.
    """
    st.info("Alternatif yÃ¶ntem: HTML elementleri taranÄ±yor...")
    brands_data = []
    # TarayÄ±cÄ± GeliÅŸtirici AraÃ§larÄ± ile filtre bÃ¶lÃ¼mÃ¼nÃ¼n container'Ä±nÄ± ve
    # marka/sayÄ± elementlerini bulup uygun seÃ§icileri belirlemek gerekir.
    # Ã–rnek (Bu seÃ§iciler SADECE TAHMÄ°NÄ°DÄ°R ve Ã§alÄ±ÅŸmayabilir):
    try:
        # Marka filtresinin genel container'Ä±nÄ± bulmaya Ã§alÄ±ÅŸalÄ±m (class adÄ± deÄŸiÅŸebilir)
        # Genellikle 'Brands' baÅŸlÄ±ÄŸÄ±nÄ± iÃ§eren bir div'in kardeÅŸ veya ebeveyn elementi olabilir.
        brand_section = soup.find('h3', string='Brands') # Veya 'h2', 'div' vb. olabilir
        if not brand_section:
             # Belki de input'larÄ±n olduÄŸu bir div'i bulabiliriz
             st.warning("DoÄŸrudan HTML'de 'Brands' baÅŸlÄ±ÄŸÄ± bulunamadÄ±.")
             filter_containers = soup.find_all('div', class_=re.compile(r'filter-section|facet-container')) # Regex ile olasÄ± class'larÄ± ara
             if not filter_containers:
                 st.error("Marka filtresi bÃ¶lÃ¼mÃ¼ HTML iÃ§inde bulunamadÄ± (Alternatif YÃ¶ntem).")
                 return None

             # Bu container'lar iÃ§inde checkbox ve label'larÄ± arayalÄ±m
             for container in filter_containers:
                 items = container.find_all('div', class_=re.compile(r'filter-item|facet-value')) # Ã–rnek class adlarÄ±
                 if items:
                      brand_section = container # Ä°lk uygun container'Ä± alalÄ±m
                      break

        if not brand_section:
             st.error("Marka filtresi bÃ¶lÃ¼mÃ¼ HTML iÃ§inde bulunamadÄ± (Alternatif YÃ¶ntem).")
             return None

        # Marka listesini iÃ§eren daha spesifik bir parent element arayalÄ±m
        parent_element = brand_section.find_parent('div') # Veya 'ul'

        # Marka checkbox'larÄ±nÄ± veya label'larÄ±nÄ± bulalÄ±m
        # input'un kardeÅŸ label'Ä± veya parent'Ä± olabilir. YapÄ±yÄ± incelemek ÅŸart.
        # Ã–rnek 1: <label><input ...> Marka (SayÄ±)</label>
        # Ã–rnek 2: <div><input ...><span>Marka</span><span>(SayÄ±)</span></div>

        # Ã–rnek 1'e benzer bir yapÄ± arayalÄ±m
        labels = parent_element.find_all('label', class_=re.compile(r'checkbox-label|facet-label'))

        if not labels:
            # Ã–rnek 2'ye benzer bir yapÄ± arayalÄ±m
            list_items = parent_element.find_all('div', class_=re.compile(r'checkbox-item|facet-item'))
            for item in list_items:
                checkbox = item.find('input', type='checkbox')
                spans = item.find_all('span')
                if checkbox and len(spans) >= 2:
                    brand_name = spans[0].get_text(strip=True)
                    count_text = spans[1].get_text(strip=True).strip('()')
                    if count_text.isdigit():
                         brands_data.append({
                            'Marka': brand_name,
                            'ÃœrÃ¼n SayÄ±sÄ±': int(count_text)
                         })

        else: # Label tabanlÄ± yapÄ±
            for label in labels:
                 text = label.get_text(strip=True)
                 # Marka adÄ±nÄ± ve sayÄ±sÄ±nÄ± ayÄ±klamak iÃ§in regex
                 match = re.search(r'^(.*?)\s*\((\d+)\)$', text)
                 if match:
                     brand_name = match.group(1).strip()
                     count = int(match.group(2))
                     brands_data.append({
                         'Marka': brand_name,
                         'ÃœrÃ¼n SayÄ±sÄ±': count
                     })

        if brands_data:
            st.success(f"{len(brands_data)} marka verisi doÄŸrudan HTML'den baÅŸarÄ±yla Ã§ekildi (Alternatif YÃ¶ntem).")
            return pd.DataFrame(brands_data)
        else:
            st.error("Marka verisi doÄŸrudan HTML elementlerinden de Ã§ekilemedi.")
            return None

    except Exception as e:
        st.error(f"MarkalarÄ± doÄŸrudan HTML'den Ã§ekerken hata oluÅŸtu (Alternatif YÃ¶ntem): {e}")
        return None

# --- Streamlit ArayÃ¼zÃ¼ ---
url = st.text_input("Sephora ÃœrÃ¼n Listeleme SayfasÄ± URL'sini Girin:", placeholder="https://www.sephora.ae/en/shop/makeup/C302")
process_button = st.button("MarkalarÄ± Ã‡ek ve CSV OluÅŸtur")

if process_button and url:
    if "sephora." not in url:
         st.warning("LÃ¼tfen geÃ§erli bir Sephora URL'si girin.")
    else:
        with st.spinner("Sayfa indiriliyor ve markalar Ã§ekiliyor... LÃ¼tfen bekleyin."):
            html_content = fetch_html(url)

            if html_content:
                df_brands = extract_brands_from_html(html_content)

                if df_brands is not None and not df_brands.empty:
                    st.subheader("Ã‡ekilen Marka Verileri")
                    st.dataframe(df_brands, use_container_width=True)

                    # CSV Ä°ndirme Butonu
                    csv_buffer = StringIO()
                    df_brands.to_csv(csv_buffer, index=False, encoding='utf-8')
                    csv_data = csv_buffer.getvalue()

                    # URL'den dosya adÄ± oluÅŸturma (basit)
                    try:
                        file_name_part = url.split('/')[-1].split('?')[0]
                        csv_filename = f"sephora_markalar_{file_name_part}.csv"
                    except:
                        csv_filename = "sephora_markalar.csv"


                    st.download_button(
                        label="ğŸ’¾ CSV Olarak Ä°ndir",
                        data=csv_data,
                        file_name=csv_filename,
                        mime='text/csv',
                    )
                elif df_brands is not None and df_brands.empty:
                     st.warning("Marka verisi bulunamadÄ±. Filtreler yÃ¼klenmemiÅŸ olabilir veya sayfa yapÄ±sÄ± farklÄ± olabilir.")
                # Hata mesajlarÄ± zaten fonksiyon iÃ§inde verildi.
            # else: HTML alÄ±namadÄ±ysa hata zaten verildi.
elif process_button and not url:
    st.warning("LÃ¼tfen bir URL girin.")

st.markdown("---")
st.caption("Not: Bu uygulama Sephora web sitesinin yapÄ±sÄ±na baÄŸlÄ±dÄ±r. Site gÃ¼ncellenirse Ã§alÄ±ÅŸmayabilir.")
