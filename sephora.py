import streamlit as st
import pandas as pd
import re
from bs4 import BeautifulSoup
import io

st.set_page_config(page_title="Sephora Marka Ã‡Ä±karÄ±cÄ±", layout="wide")

st.title("ğŸ’„ Sephora Marka Filtresi Veri Ã‡Ä±karÄ±cÄ±")
st.write("LÃ¼tfen Sephora Ã¼rÃ¼n listeleme sayfasÄ±nÄ±n indirilmiÅŸ HTML dosyasÄ±nÄ± yÃ¼kleyin.")
st.caption("Ã–rnek dosya: 'Makeup Essentials_ Lips, Eyes & Skin â‰¡ Sephora.html'")

def extract_brands_from_html_elements(html_content):
    """
    Parses HTML content string to find brand filter elements directly within the HTML structure.
    Looks for checkboxes and associated labels containing brand names and counts.

    Args:
        html_content (str): The HTML content as a string.

    Returns:
        tuple: A tuple containing (list of brand dictionaries, list of headers)
               or (None, None) if data extraction fails.
    """
    try:
        soup = BeautifulSoup(html_content, 'lxml')
    except Exception as e:
        st.warning(f"lxml parser ile HTML ayrÄ±ÅŸtÄ±rÄ±lÄ±rken hata (html.parser deneniyor): {e}")
        try:
            soup = BeautifulSoup(html_content, 'html.parser')
        except Exception as e2:
             st.error(f"HTML ayrÄ±ÅŸtÄ±rÄ±lamadÄ±: {e2}")
             return None, None

    brands_data = []
    fieldnames = ['Marka', 'Urun Adedi']

    st.write("HTML elemanlarÄ± iÃ§inde marka filtresi aranÄ±yor...")

    # Potansiyel olarak filtreleri iÃ§eren bÃ¶lÃ¼mÃ¼ bulmaya Ã§alÄ±ÅŸalÄ±m.
    # Bu kÄ±sÄ±m sitenin yapÄ±sÄ±na gÃ¶re deÄŸiÅŸebilir, daha genel seÃ§iciler deneyelim.
    # Ã–rnek: Filtre baÅŸlÄ±ÄŸÄ±nÄ±n 'Brands' olduÄŸu bir bÃ¶lÃ¼m arayabiliriz.
    brands_section = None
    possible_headers = soup.find_all(['h2', 'h3', 'h4', 'button', 'div'], string=re.compile(r'^\s*Brands\s*$', re.IGNORECASE))

    if not possible_headers:
        st.warning("HTML iÃ§inde 'Brands' baÅŸlÄ±ÄŸÄ±na sahip belirgin bir bÃ¶lÃ¼m bulunamadÄ±. Checkbox'lar aranacak.")
        # Alternatif: DoÄŸrudan checkbox'larÄ± arayalÄ±m
        filter_elements = soup.find_all('div', {'data-testid': re.compile(r'facet-filter-container', re.IGNORECASE)}) # TestID'den yola Ã§Ä±kalÄ±m
        if not filter_elements:
            filter_elements = soup.find_all('input', {'type':'checkbox'}) # En genel arama
            st.info(f"TestID bulunamadÄ±, {len(filter_elements)} adet checkbox bulundu.")
    else:
        # BaÅŸlÄ±k bulunduysa, onun ebeveynini veya yakÄ±nÄ±ndaki liste elemanÄ±nÄ± bulmaya Ã§alÄ±ÅŸalÄ±m
        st.info(f"'Brands' baÅŸlÄ±ÄŸÄ± iÃ§eren {len(possible_headers)} element bulundu. Ä°lk bulunanÄ±n etrafÄ± taranacak.")
        # Genellikle filtreler baÅŸlÄ±ÄŸÄ±n kardeÅŸ veya ebeveyninin iÃ§indedir.
        # Bu kÄ±sÄ±m daha karmaÅŸÄ±k hale gelebilir ve sitenin yapÄ±sÄ±na baÄŸlÄ±dÄ±r.
        # Åimdilik basitÃ§e tÃ¼m checkbox'larÄ± aramaya devam edelim, ancak baÅŸlÄ±ÄŸÄ±n bulunmasÄ± iyiye iÅŸaret.
        filter_elements = soup.find_all('input', {'type':'checkbox'}) # Yine de tÃ¼m checkbox'larÄ± arayalÄ±m

    # Marka adÄ±nÄ± ve sayÄ±sÄ±nÄ± iÃ§eren kalÄ±bÄ± bulmak iÃ§in regex
    # Ã–rnek: "BRAND NAME (123)"
    brand_pattern = re.compile(r'^(.*?)\s*\((\d+)\)\s*$')

    processed_labels = set() # AynÄ± label'Ä± tekrar iÅŸlememek iÃ§in

    for element in filter_elements:
        # Checkbox'Ä±n iliÅŸkili label'Ä±nÄ± bulmaya Ã§alÄ±ÅŸalÄ±m
        label_element = None
        # 1. 'id' varsa ve 'for' ile eÅŸleÅŸen label varsa
        if element.has_attr('id'):
            label_element = soup.find('label', {'for': element['id']})

        # 2. Label checkbox'Ä± kapsÄ±yorsa (ebeveyn ise)
        if not label_element and element.parent and element.parent.name == 'label':
            label_element = element.parent

        # 3. Checkbox ile aynÄ± seviyede veya yakÄ±nÄ±nda bir label/span varsa (daha az gÃ¼venilir)
        if not label_element:
             sibling_label = element.find_next_sibling(['label', 'span'])
             if sibling_label:
                 label_element = sibling_label
             else:
                 parent_label = element.find_parent(['label', 'div']) # YakÄ±ndaki bir div'i de kontrol et
                 if parent_label:
                     # Ä°Ã§inde sadece bu checkbox ve metin olup olmadÄ±ÄŸÄ±nÄ± kontrol et
                     if parent_label.find('input', {'type':'checkbox'}) == element:
                          label_element = parent_label


        if label_element:
            label_text = label_element.get_text(strip=True)

            # EÄŸer bu label daha Ã¶nce iÅŸlendiyse atla
            if label_text in processed_labels:
                continue
            processed_labels.add(label_text)

            match = brand_pattern.match(label_text)
            if match:
                brand_name = match.group(1).strip()
                hit_count = int(match.group(2))
                # Marka adÄ±nÄ±n mantÄ±klÄ± gÃ¶rÃ¼nÃ¼p gÃ¶rÃ¼nmediÄŸini kontrol et (Ã¶rn. tek harf olmamalÄ±)
                if len(brand_name) > 1:
                    brands_data.append({
                        fieldnames[0]: brand_name,
                        fieldnames[1]: hit_count
                    })
                    # st.write(f"Bulundu: {brand_name} ({hit_count})") # Debug

    if not brands_data:
        st.error("HTML elemanlarÄ± (checkbox/label) iÃ§inde marka ve Ã¼rÃ¼n sayÄ±sÄ± bilgisi bulunamadÄ±. Sayfa yapÄ±sÄ± beklenenden farklÄ± olabilir veya veri script iÃ§inde farklÄ± bir formatta bulunuyor olabilir.")
        return None, None

    st.info(f"Toplam {len(brands_data)} marka bulundu.")
    return brands_data, fieldnames

# --- Streamlit File Uploader ---
uploaded_file = st.file_uploader("HTML DosyasÄ±nÄ± Buraya SÃ¼rÃ¼kleyin veya SeÃ§in", type=["html", "htm"])

if uploaded_file is not None:
    try:
        stringio = io.StringIO(uploaded_file.getvalue().decode("utf-8"))
        html_content = stringio.read()
        st.success(f"'{uploaded_file.name}' baÅŸarÄ±yla yÃ¼klendi ve okundu.")

        with st.spinner("Marka verileri Ã§Ä±karÄ±lÄ±yor..."):
            # Yeni fonksiyonu Ã§aÄŸÄ±r
            brands_data, headers = extract_brands_from_html_elements(html_content)

        if brands_data and headers:
            st.success("Marka verileri baÅŸarÄ±yla Ã§Ä±karÄ±ldÄ±!")
            df = pd.DataFrame(brands_data)
            # Markaya gÃ¶re sÄ±rala
            df = df.sort_values(by='Marka').reset_index(drop=True)
            st.dataframe(df, use_container_width=True)
            csv_string = df.to_csv(index=False, encoding='utf-8-sig')
            st.download_button(
               label="CSV Olarak Ä°ndir",
               data=csv_string,
               file_name='sephora_markalar.csv',
               mime='text/csv',
            )
        # else: # Hata mesajÄ± fonksiyon iÃ§inde veriliyor

    except UnicodeDecodeError:
        st.error("Dosya kodlamasÄ± UTF-8 deÄŸil gibi gÃ¶rÃ¼nÃ¼yor. LÃ¼tfen UTF-8 formatÄ±nda kaydedilmiÅŸ bir HTML dosyasÄ± yÃ¼kleyin.")
    except Exception as e:
        st.error(f"Dosya iÅŸlenirken genel bir hata oluÅŸtu: {e}")
        st.exception(e)
