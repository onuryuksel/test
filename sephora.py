import streamlit as st
from bs4 import BeautifulSoup
import pandas as pd
import re
import json
from io import StringIO
import os

# ... (Sayfa BaÅŸlÄ±ÄŸÄ±, Talimatlar vb. aynÄ± kalabilir) ...
st.set_page_config(page_title="Sephora Marka Filtre Ã‡ekici", layout="wide")
st.title("ğŸ’„ Sephora Marka Filtre Veri Ã‡ekici (HTML YÃ¼kleme)")
st.caption("KaydettiÄŸiniz Sephora Ã¼rÃ¼n listeleme sayfasÄ± HTML dosyasÄ±nÄ± yÃ¼kleyerek marka filtresindeki verileri CSV olarak indirin.")
st.info("""
**NasÄ±l KullanÄ±lÄ±r:**
1.  Marka filtrelerini Ã§ekmek istediÄŸiniz Sephora Ã¼rÃ¼n listeleme sayfasÄ±nÄ± (Ã¶rn: Makyaj, ParfÃ¼m kategorisi) **web tarayÄ±cÄ±nÄ±zda** aÃ§Ä±n.
2.  SayfanÄ±n **tamamen** yÃ¼klendiÄŸinden emin olun (sol taraftaki **"Refine"** veya benzeri bÃ¶lÃ¼mdeki **"Brands"** filtresinin ve markalarÄ±n gÃ¶rÃ¼nÃ¼r olduÄŸundan emin olun).
3.  TarayÄ±cÄ±da sayfaya saÄŸ tÄ±klayÄ±n ve **"FarklÄ± Kaydet" (Save Page As...)** seÃ§eneÄŸini seÃ§in.
4.  KayÄ±t tÃ¼rÃ¼ olarak **"Web SayfasÄ±, Sadece HTML" (Webpage, HTML Only)** seÃ§eneÄŸini seÃ§in. Dosya uzantÄ±sÄ± `.html` veya `.htm` olmalÄ±dÄ±r.
5.  KaydettiÄŸiniz bu `.html` dosyasÄ±nÄ± aÅŸaÄŸÄ±daki "GÃ¶zat" dÃ¼ÄŸmesini kullanarak yÃ¼kleyin.
""")

def find_nested_data(data, target_key, target_value):
    """Ä°Ã§ iÃ§e geÃ§miÅŸ dict/list'lerde belirli bir anahtar-deÄŸer Ã§iftini arar."""
    if isinstance(data, dict):
        if data.get(target_key) == target_value:
            return data
        for key, value in data.items():
            found = find_nested_data(value, target_key, target_value)
            if found: return found
    elif isinstance(data, list):
        for item in data:
            found = find_nested_data(item, target_key, target_value)
            if found: return found
    return None

def extract_brands_from_potential_next_data(soup):
    """ID'siz olarak __NEXT_DATA__ benzeri script'leri bulup iÅŸlemeyi dener."""
    st.info("__NEXT_DATA__ ID'li script bulunamadÄ±, potansiyel veri scriptleri aranÄ±yor...")
    scripts = soup.find_all('script')
    st.info(f"Toplam {len(scripts)} script etiketi bulundu.")
    potential_data_script = None

    for script in scripts:
        # Ä°Ã§eriÄŸi al ve kontrol et (boÅŸ etiketleri atla)
        script_content = script.string
        if script_content:
            script_content = script_content.strip()
            # Ä°Ã§eriÄŸin JSON'a benzeyip benzemediÄŸini kontrol et (basit kontrol)
            if script_content.startswith('{') and script_content.endswith('}') and 'props' in script_content[:500] and 'pageProps' in script_content[:1000]:
                 st.info("JSON'a benzeyen ve 'props', 'pageProps' iÃ§eren bir script bulundu.")
                 potential_data_script = script_content
                 break # Ä°lk uygun olanÄ± al

    if not potential_data_script:
        st.warning("JSON iÃ§eren potansiyel __NEXT_DATA__ script'i bulunamadÄ±.")
        return None

    # JSON ayrÄ±ÅŸtÄ±rma ve veri Ã§Ä±karma (Ã¶ncekiyle aynÄ± mantÄ±k)
    brands_data = []
    processed_brands = set()
    try:
        next_data = json.loads(potential_data_script)
        st.success("Potansiyel veri scripti JSON olarak baÅŸarÄ±yla ayrÄ±ÅŸtÄ±rÄ±ldÄ±.")
        brand_filter_dict = find_nested_data(next_data, 'attributeId', 'c_brand')

        if brand_filter_dict:
            st.success("'c_brand' attributeId iÃ§eren yapÄ± bulundu.")
            if 'values' in brand_filter_dict and isinstance(brand_filter_dict['values'], list):
                st.info(f"Marka 'values' listesinde {len(brand_filter_dict['values'])} Ã¶ÄŸe bulundu.")
                for item in brand_filter_dict['values']:
                     if isinstance(item, dict) and 'label' in item and 'hitCount' in item:
                         brand_name = item['label'].strip()
                         hit_count = item['hitCount']
                         if brand_name and isinstance(hit_count, int) and brand_name.lower() != 'no' and brand_name not in processed_brands:
                             brands_data.append({'Marka': brand_name, 'ÃœrÃ¼n SayÄ±sÄ±': hit_count})
                             processed_brands.add(brand_name)
                if brands_data:
                    st.info(f"{len(brands_data)} geÃ§erli marka/sayÄ± Ã§ifti potansiyel __NEXT_DATA__ iÃ§inden ayÄ±klandÄ±.")
                    return pd.DataFrame(brands_data)
                else:
                    st.warning("Marka filtresi ('c_brand') bulundu ancak geÃ§erli Ã¶ÄŸe yoktu.")
                    return pd.DataFrame()
            else:
                st.warning("'c_brand' yapÄ±sÄ± bulundu ancak 'values' listesi yok.")
                return None
        else:
            st.warning("Potansiyel veri scripti iÃ§inde 'c_brand' yapÄ±sÄ± bulunamadÄ±.")
            return None
    except Exception as e:
        st.error(f"Potansiyel __NEXT_DATA__ iÅŸlenirken hata: {e}")
        return None

def extract_brands_directly_very_generic(soup):
    """Ã‡OK GENEL Alternatif yÃ¶ntem: Sayfadaki tÃ¼m label'larÄ± tarar."""
    st.info("En genel alternatif yÃ¶ntem deneniyor (tÃ¼m label'lar taranÄ±yor)...")
    brands_data = []
    processed_brands = set()

    # Sayfadaki TÃœM label elementlerini bul
    all_labels = soup.find_all('label')
    st.info(f"Toplam {len(all_labels)} label etiketi bulundu.")

    if not all_labels:
        st.error("HTML iÃ§inde hiÃ§ label etiketi bulunamadÄ±.")
        return None

    found_count = 0
    for label in all_labels:
        # Label'Ä±n iÃ§inde checkbox var mÄ± diye kontrol et (daha olasÄ±)
        checkbox = label.find('input', type='checkbox')
        # Checkbox yoksa bile metni kontrol et
        text_content = label.get_text(separator=' ', strip=True)
        # Regex: Marka AdÄ± (SayÄ±) formatÄ±nÄ± ara
        match = re.search(r'([a-zA-Z0-9 &\'\+\.-]+)\s*\((\d+)\)$', text_content)
        if match:
            brand_name = match.group(1).strip()
            count = int(match.group(2))
            # EÄŸer checkbox varsa veya marka adÄ± makul gÃ¶rÃ¼nÃ¼yorsa ekle
            if checkbox or len(brand_name) > 1 : # Sadece checkbox olanlarÄ± veya 1 karakterden uzun markalarÄ± al
                 if brand_name and brand_name.lower() not in ['no', 'yes'] and brand_name not in processed_brands:
                     brands_data.append({'Marka': brand_name, 'ÃœrÃ¼n SayÄ±sÄ±': count})
                     processed_brands.add(brand_name)
                     found_count += 1

    if brands_data:
        st.success(f"{len(brands_data)} olasÄ± marka verisi HTML'deki label'lardan ayÄ±klandÄ±.")
        return pd.DataFrame(brands_data)
    else:
        st.warning("Genel HTML taramasÄ±nda (label'lar) yapÄ±sal marka verisi bulunamadÄ±.")
        return None


# --- Streamlit ArayÃ¼zÃ¼ ---
uploaded_file = st.file_uploader(
    "KaydedilmiÅŸ Sephora HTML DosyasÄ±nÄ± YÃ¼kleyin (.html/.htm)",
    type=["html", "htm"],
    accept_multiple_files=False
)

if uploaded_file is not None:
    st.success(f"'{uploaded_file.name}' baÅŸarÄ±yla yÃ¼klendi.")
    with st.spinner("HTML dosyasÄ± okunuyor ve markalar ayrÄ±ÅŸtÄ±rÄ±lÄ±yor..."):
        df_brands = None
        html_content = None
        try:
            html_content_bytes = uploaded_file.getvalue()
            try:
                html_content = html_content_bytes.decode("utf-8")
            except UnicodeDecodeError:
                st.warning("UTF-8 ile decode edilemedi, latin-1 deneniyor...")
                html_content = html_content_bytes.decode("latin-1")
            st.info("HTML iÃ§eriÄŸi okundu.")
        except Exception as e:
             st.error(f"Dosya okunurken/decode edilirken hata oluÅŸtu: {e}")

        if html_content:
            try:
                 soup = BeautifulSoup(html_content, 'lxml')
                 st.info("HTML, BeautifulSoup ile parse edildi.")

                 # Ã–nce potansiyel __NEXT_DATA__ script'lerini dene
                 df_brands = extract_brands_from_potential_next_data(soup)

                 # O baÅŸarÄ±sÄ±z olursa veya boÅŸ dÃ¶nerse en genel HTML tarama yÃ¶ntemini dene
                 if df_brands is None or df_brands.empty:
                      if df_brands is None:
                           st.info("__NEXT_DATA__ benzeri script bulunamadÄ±/iÅŸlenemedi, en genel HTML tarama deneniyor.")
                      else:
                           st.info("__NEXT_DATA__ benzeri script iÅŸlendi ancak veri bulunamadÄ±, en genel HTML tarama deneniyor.")
                      try:
                          df_brands = extract_brands_directly_very_generic(soup)
                      except Exception as e:
                          st.error(f"En genel HTML ayrÄ±ÅŸtÄ±rma yÃ¶nteminde hata oluÅŸtu: {e}")
                          df_brands = None

                 # Sonucu gÃ¶ster ve CSV indir
                 if df_brands is not None and not df_brands.empty:
                     st.subheader("Ã‡ekilen Marka Verileri")
                     st.dataframe(df_brands.set_index('Marka'), use_container_width=True)
                     # --- CSV Ä°ndirme ---
                     try:
                         csv_buffer = StringIO()
                         df_brands.to_csv(csv_buffer, index=False, encoding='utf-8')
                         csv_data = csv_buffer.getvalue()
                         base_filename = os.path.splitext(uploaded_file.name)[0]
                         csv_filename = f"sephora_markalar_{base_filename}.csv"
                         st.download_button(
                             label="ğŸ’¾ CSV Olarak Ä°ndir",
                             data=csv_data,
                             file_name=csv_filename,
                             mime='text/csv',
                         )
                     except Exception as e:
                         st.error(f"CSV oluÅŸturulurken/indirilirken hata: {e}")
                 elif df_brands is not None: # BoÅŸ DataFrame geldiyse
                      st.warning("YÃ¼klenen HTML dosyasÄ±nda, denenen yÃ¶ntemlerle marka filtresi verisi bulunamadÄ±.")
                 # else: df_brands = None ise hata zaten yukarÄ±da gÃ¶sterildi.

            except Exception as e:
                st.error(f"HTML iÃ§eriÄŸi BeautifulSoup ile parse edilirken hata oluÅŸtu: {e}")

st.markdown("---")
st.caption("Not: BaÅŸarÄ±sÄ±z olursa, HTML dosyasÄ±nÄ± tarayÄ±cÄ±da aÃ§Ä±p 'Brands' filtresinin olduÄŸu bÃ¶lÃ¼mÃ¼n HTML kodunu inceleyerek manuel kontrol edebilirsiniz.")
