import streamlit as st
from bs4 import BeautifulSoup
import pandas as pd
import re
import json
from io import StringIO
import os

# Sayfa BaÅŸlÄ±ÄŸÄ±
st.set_page_config(page_title="Sephora Marka Filtre Ã‡ekici", layout="wide")
st.title("ğŸ’„ Sephora Marka Filtre Veri Ã‡ekici (HTML YÃ¼kleme)2")
st.caption("KaydettiÄŸiniz Sephora Ã¼rÃ¼n listeleme sayfasÄ± HTML dosyasÄ±nÄ± yÃ¼kleyerek marka filtresindeki verileri CSV olarak indirin.")

# --- KullanÄ±cÄ± TalimatlarÄ± ---
st.info("""
**NasÄ±l KullanÄ±lÄ±r:**
1.  Marka filtrelerini Ã§ekmek istediÄŸiniz Sephora Ã¼rÃ¼n listeleme sayfasÄ±nÄ± **web tarayÄ±cÄ±nÄ±zda** aÃ§Ä±n.
2.  SayfanÄ±n **tamamen** yÃ¼klendiÄŸinden emin olun (sol taraftaki **"Refine"** veya benzeri bÃ¶lÃ¼mdeki **"Brands"** filtresinin ve markalarÄ±n gÃ¶rÃ¼nÃ¼r olduÄŸundan emin olun).
3.  TarayÄ±cÄ±da sayfaya saÄŸ tÄ±klayÄ±n ve **"FarklÄ± Kaydet" (Save Page As...)** seÃ§eneÄŸini seÃ§in.
4.  KayÄ±t tÃ¼rÃ¼ olarak **"Web SayfasÄ±, Sadece HTML" (Webpage, HTML Only)** seÃ§eneÄŸini seÃ§in. Dosya uzantÄ±sÄ± `.html` veya `.htm` olmalÄ±dÄ±r. (EÄŸer bu Ã§alÄ±ÅŸmazsa "Web SayfasÄ±, TamamÄ±" deneyebilirsiniz ama ilk tercih "Sadece HTML" olmalÄ±).
5.  KaydettiÄŸiniz bu `.html` dosyasÄ±nÄ± aÅŸaÄŸÄ±daki "GÃ¶zat" dÃ¼ÄŸmesini kullanarak yÃ¼kleyin.
""")

# --- Fonksiyonlar ---

def find_nested_data(data, target_key, target_value):
    """Ä°Ã§ iÃ§e geÃ§miÅŸ dict/list'lerde belirli bir anahtar-deÄŸer Ã§iftini arar."""
    if isinstance(data, dict):
        if data.get(target_key) == target_value:
            return data
        for key, value in data.items():
            found = find_nested_data(value, target_key, target_value)
            if found: return found
    elif isinstance(data, list):
        for item in data:
            found = find_nested_data(item, target_key, target_value)
            if found: return found
    return None

def extract_brands_from_next_data(soup):
    """__NEXT_DATA__ script'inden marka verilerini Ã§Ä±karÄ±r."""
    brands_data = []
    processed_brands = set()
    script_tag = soup.find('script', id='__NEXT_DATA__')

    if not script_tag:
        st.warning("__NEXT_DATA__ script etiketi HTML iÃ§inde bulunamadÄ±.")
        return None

    st.info("__NEXT_DATA__ script etiketi bulundu.")
    script_content = script_tag.string # .string iÃ§eriÄŸi alÄ±r

    # Debug: Script iÃ§eriÄŸini kontrol et
    if script_content:
        script_content = script_content.strip() # BaÅŸtaki/sondaki boÅŸluklarÄ± temizle
        st.info(f"__NEXT_DATA__ iÃ§eriÄŸinin baÅŸÄ± (ilk 500 karakter):\n```json\n{script_content[:500]}...\n```")
        if not script_content: # strip() sonrasÄ± boÅŸ kalmÄ±ÅŸsa
             st.error("__NEXT_DATA__ etiketi bulundu ancak iÃ§eriÄŸi boÅŸ veya sadece boÅŸluklardan oluÅŸuyor.")
             return None
    else:
        st.error("__NEXT_DATA__ etiketi bulundu ancak .string ile iÃ§erik alÄ±namadÄ± (None dÃ¶ndÃ¼). Etiket yapÄ±sÄ± beklenenden farklÄ± olabilir.")
        # Alternatif olarak get_text() deneyebiliriz ama genellikle .string yeterli olmalÄ±
        # script_content_alt = script_tag.get_text(strip=True)
        # if script_content_alt: ...
        return None

    # JSON ayrÄ±ÅŸtÄ±rmayÄ± dene
    try:
        next_data = json.loads(script_content)
        st.success("__NEXT_DATA__ iÃ§eriÄŸi JSON olarak baÅŸarÄ±yla ayrÄ±ÅŸtÄ±rÄ±ldÄ±.")

        # 'attributeId': 'c_brand' iÃ§eren yapÄ±yÄ± bul
        brand_filter_dict = find_nested_data(next_data, 'attributeId', 'c_brand')

        if brand_filter_dict:
            st.success("'c_brand' attributeId iÃ§eren yapÄ± bulundu.")
            if 'values' in brand_filter_dict and isinstance(brand_filter_dict['values'], list):
                st.info(f"Marka 'values' listesinde {len(brand_filter_dict['values'])} Ã¶ÄŸe bulundu.")
                for item in brand_filter_dict['values']:
                    if isinstance(item, dict) and 'label' in item and 'hitCount' in item:
                        brand_name = item['label'].strip()
                        hit_count = item['hitCount']
                        if brand_name and isinstance(hit_count, int) and brand_name.lower() != 'no' and brand_name not in processed_brands:
                            brands_data.append({'Marka': brand_name, 'ÃœrÃ¼n SayÄ±sÄ±': hit_count})
                            processed_brands.add(brand_name)
                if brands_data:
                    st.info(f"{len(brands_data)} geÃ§erli marka/sayÄ± Ã§ifti __NEXT_DATA__ iÃ§inden ayÄ±klandÄ±.")
                    return pd.DataFrame(brands_data)
                else:
                    st.warning("__NEXT_DATA__ iÃ§inde marka filtresi ('c_brand') bulundu ancak geÃ§erli marka/sayÄ± Ã§ifti iÃ§ermiyordu.")
                    return pd.DataFrame() # BoÅŸ DataFrame
            else:
                st.warning("'c_brand' yapÄ±sÄ± bulundu ancak geÃ§erli bir 'values' listesi iÃ§ermiyor.")
                return None
        else:
            st.warning("__NEXT_DATA__ iÃ§inde 'c_brand' attributeId'li filtre yapÄ±sÄ± bulunamadÄ±.")
            return None

    except json.JSONDecodeError as e:
        st.error(f"__NEXT_DATA__ iÃ§eriÄŸi JSON olarak ayrÄ±ÅŸtÄ±rÄ±lamadÄ±: {e}")
        st.error("HatanÄ±n oluÅŸtuÄŸu yerdeki iÃ§erik (ilk 100 karakter): " + repr(script_content[:100]))
        st.warning("HTML dosyasÄ±nÄ±n tarayÄ±cÄ±dan 'Web SayfasÄ±, Sadece HTML' olarak doÄŸru ÅŸekilde kaydedildiÄŸinden emin olun.")
        return None
    except Exception as e:
        st.error(f"__NEXT_DATA__ iÅŸlenirken beklenmedik bir hata oluÅŸtu: {e}")
        return None

def extract_brands_directly(soup):
    """Alternatif yÃ¶ntem: DoÄŸrudan HTML elementlerini parse etmeye Ã§alÄ±ÅŸÄ±r."""
    st.info("Alternatif yÃ¶ntem (doÄŸrudan HTML elementleri) deneniyor...")
    brands_data = []
    processed_brands = set()

    # 1. AdÄ±m: "Brands" baÅŸlÄ±ÄŸÄ±nÄ± veya benzerini iÃ§eren bÃ¶lÃ¼mÃ¼ bulmaya Ã§alÄ±ÅŸ
    brand_section = None
    # CSS seÃ§icileri deneyelim (daha spesifik olabilir)
    css_selectors = [
        'div[data-testid="facet-container-Brands"]', # OlasÄ± bir test ID'si
        'div[data-testid="Brands"]',
        'div[aria-labelledby*="brand"]', # 'brand' iÃ§eren aria-labelledby
        'section[aria-labelledby*="brand"]',
        'aside[aria-labelledby*="brand"]'
    ]
    for selector in css_selectors:
        found_section = soup.select_one(selector)
        if found_section:
            brand_section = found_section
            st.info(f"Potansiyel filtre bÃ¶lÃ¼mÃ¼ CSS seÃ§ici ile bulundu: '{selector}'")
            break

    # CSS seÃ§icileri baÅŸarÄ±sÄ±z olursa, metin iÃ§eriÄŸi ile ara
    if not brand_section:
        st.warning("CSS seÃ§icileri ile filtre bÃ¶lÃ¼mÃ¼ bulunamadÄ±, metin aramasÄ± yapÄ±lÄ±yor...")
        possible_headers = soup.find_all(['h3', 'h2', 'button', 'div'], string=re.compile(r'^\s*Brands?\s*$', re.IGNORECASE))
        for header in possible_headers:
            # Bulunan baÅŸlÄ±ÄŸÄ±n etrafÄ±ndaki parent elementleri kontrol et
            current = header
            for _ in range(5): # En fazla 5 seviye yukarÄ± bak
                parent = current.find_parent(['div', 'section', 'aside'])
                # Parent iÃ§inde checkbox veya list item gibi filtre Ã¶ÄŸeleri var mÄ±?
                if parent and (parent.find('input', type='checkbox') or len(parent.find_all('li')) > 2):
                    brand_section = parent
                    st.info(f"'Brands' baÅŸlÄ±ÄŸÄ±ndan yola Ã§Ä±karak parent bulundu: <{brand_section.name} class='{brand_section.get('class', 'N/A')}' id='{brand_section.get('id', 'N/A')}'>")
                    break
                if not parent: break
                current = parent
            if brand_section: break

    if not brand_section:
        st.error("Marka filtresi bÃ¶lÃ¼mÃ¼ HTML iÃ§inde otomatik olarak tespit edilemedi (Alternatif YÃ¶ntem).")
        return None

    # 2. AdÄ±m: Filtre bÃ¶lÃ¼mÃ¼ iÃ§inde marka Ã¶ÄŸelerini bul
    # Checkbox'larÄ± iÃ§eren label'larÄ± veya div'leri hedefle
    items = brand_section.find_all('label', class_=re.compile(r'checkbox|facet', re.IGNORECASE))
    if not items:
        # Input'larÄ±n parent'larÄ±nÄ± dene
        inputs = brand_section.find_all('input', type='checkbox')
        items = [inp.find_parent(['label','div','li']) for inp in inputs if inp.find_parent(['label','div','li'])]
    if not items:
         # Sadece list item'larÄ±nÄ± dene (daha genel)
        items = brand_section.find_all('li')
    if not items:
        # En genel: iÃ§inde (sayÄ±) olan div'leri ara
        items = brand_section.find_all('div', text=re.compile(r'\(\d+\)\s*$'))


    if not items:
        st.error("Marka listesi elementleri bulunamadÄ±.")
        return None

    st.info(f"Bulunan olasÄ± marka elementi sayÄ±sÄ±: {len(items)}")

    for item in items:
        text_content = item.get_text(separator=' ', strip=True)
        # Regex: Marka AdÄ± (SayÄ±) formatÄ±nÄ± ara
        # BaÅŸÄ±nda/sonunda ekstra karakterler olabileceÄŸini varsayalÄ±m
        match = re.search(r'([a-zA-Z0-9 &\'\+\.-]+)\s*\((\d+)\)', text_content)
        if match:
            brand_name = match.group(1).strip()
            count = int(match.group(2))
            if brand_name and brand_name.lower() not in ['no', 'yes'] and brand_name not in processed_brands:
                brands_data.append({'Marka': brand_name, 'ÃœrÃ¼n SayÄ±sÄ±': count})
                processed_brands.add(brand_name)

    if brands_data:
        st.success(f"{len(brands_data)} marka verisi doÄŸrudan HTML'den baÅŸarÄ±yla Ã§ekildi.")
        return pd.DataFrame(brands_data)
    else:
        st.warning("DoÄŸrudan HTML taramasÄ±nda yapÄ±sal marka verisi bulunamadÄ± veya ayÄ±klanamadÄ±.")
        return None

# --- Streamlit ArayÃ¼zÃ¼ ---
uploaded_file = st.file_uploader(
    "KaydedilmiÅŸ Sephora HTML DosyasÄ±nÄ± YÃ¼kleyin (.html/.htm)",
    type=["html", "htm"],
    accept_multiple_files=False
)

if uploaded_file is not None:
    st.success(f"'{uploaded_file.name}' baÅŸarÄ±yla yÃ¼klendi.")
    with st.spinner("HTML dosyasÄ± okunuyor ve markalar ayrÄ±ÅŸtÄ±rÄ±lÄ±yor..."):
        df_brands = None
        html_content = None
        try:
            html_content_bytes = uploaded_file.getvalue()
            # UTF-8 decode etmeyi dene, olmazsa latin-1 gibi baÅŸka bir encoding dene
            try:
                html_content = html_content_bytes.decode("utf-8")
            except UnicodeDecodeError:
                st.warning("UTF-8 ile decode edilemedi, latin-1 deneniyor...")
                html_content = html_content_bytes.decode("latin-1") # Veya windows-1252 vb.
            st.info("HTML iÃ§eriÄŸi baÅŸarÄ±yla okundu.")

        except Exception as e:
             st.error(f"Dosya okunurken/decode edilirken hata oluÅŸtu: {e}")

        if html_content:
            # BeautifulSoup ile parse et
            try:
                 soup = BeautifulSoup(html_content, 'lxml')
                 st.info("HTML, BeautifulSoup ile baÅŸarÄ±yla parse edildi.")

                 # Ã–nce __NEXT_DATA__ dene
                 df_brands = extract_brands_from_next_data(soup) # Soup objesini verelim

                 # __NEXT_DATA__ baÅŸarÄ±sÄ±z olursa veya boÅŸ dÃ¶nerse alternatif yÃ¶ntemi dene
                 if df_brands is None or df_brands.empty:
                      if df_brands is None:
                           st.info("__NEXT_DATA__ bulunamadÄ± veya iÅŸlenemedi, doÄŸrudan HTML deneniyor.")
                      else: # BoÅŸ DataFrame dÃ¶ndÃ¼
                           st.info("__NEXT_DATA__ iÅŸlendi ancak veri bulunamadÄ±, doÄŸrudan HTML deneniyor.")

                      try:
                          df_brands = extract_brands_directly(soup) # AynÄ± soup objesini kullan
                      except Exception as e:
                          st.error(f"Alternatif HTML ayrÄ±ÅŸtÄ±rma yÃ¶nteminde hata oluÅŸtu: {e}")
                          df_brands = None

                 # Sonucu gÃ¶ster ve CSV indir
                 if df_brands is not None and not df_brands.empty:
                     st.subheader("Ã‡ekilen Marka Verileri")
                     st.dataframe(df_brands.set_index('Marka'), use_container_width=True)
                     # --- CSV Ä°ndirme ---
                     try:
                         csv_buffer = StringIO()
                         df_brands.to_csv(csv_buffer, index=False, encoding='utf-8')
                         csv_data = csv_buffer.getvalue()
                         base_filename = os.path.splitext(uploaded_file.name)[0]
                         csv_filename = f"sephora_markalar_{base_filename}.csv"
                         st.download_button(
                             label="ğŸ’¾ CSV Olarak Ä°ndir",
                             data=csv_data,
                             file_name=csv_filename,
                             mime='text/csv',
                         )
                     except Exception as e:
                         st.error(f"CSV oluÅŸturulurken/indirilirken hata: {e}")
                 elif df_brands is not None: # BoÅŸ DataFrame geldiyse
                      st.warning("YÃ¼klenen HTML dosyasÄ±nda, her iki yÃ¶ntemle de (__NEXT_DATA__ veya doÄŸrudan HTML tarama) marka filtresi verisi bulunamadÄ± veya ayÄ±klanamadÄ±. LÃ¼tfen HTML'i doÄŸru kaydettiÄŸinizden emin olun.")
                 # else: df_brands = None ise hata zaten yukarÄ±da verildi.

            except Exception as e:
                st.error(f"HTML iÃ§eriÄŸi BeautifulSoup ile parse edilirken hata oluÅŸtu: {e}")


st.markdown("---")
st.caption("Not: Bu uygulama, yÃ¼klediÄŸiniz HTML dosyasÄ±nÄ±n iÃ§indeki verilere dayanÄ±r. En iyi sonuÃ§ iÃ§in sayfayÄ± tarayÄ±cÄ±da **tamamen yÃ¼klendikten sonra** 'FarklÄ± Kaydet -> Web SayfasÄ±, Sadece HTML' olarak kaydedin.")
