import streamlit as st
import pandas as pd
import re
import json
from bs4 import BeautifulSoup
import io

st.set_page_config(page_title="Sephora Marka Ã‡Ä±karÄ±cÄ±", layout="wide")

st.title("ğŸ’„ Sephora Marka Filtresi Veri Ã‡Ä±karÄ±cÄ±")
st.write("LÃ¼tfen Sephora Ã¼rÃ¼n listeleme sayfasÄ±nÄ±n indirilmiÅŸ HTML dosyasÄ±nÄ± yÃ¼kleyin.")
st.caption("Ã–rnek dosya: 'Makeup Essentials_ Lips, Eyes & Skin â‰¡ Sephora.html'")

def extract_brands_from_html_content(html_content):
    """
    Parses HTML content string to find embedded brand filter data within a script tag,
    extracts brand names and their hit counts using .get_text() and simplified regex.

    Args:
        html_content (str): The HTML content as a string.

    Returns:
        tuple: A tuple containing (list of brand dictionaries, list of headers)
               or (None, None) if data extraction fails.
    """
    soup = BeautifulSoup(html_content, 'lxml') # lxml parser'Ä± deneyelim
    scripts = soup.find_all('script')

    brands_data = []
    found_data = False
    fieldnames = ['Marka', 'Urun Adedi'] # CSV baÅŸlÄ±klarÄ±

    # BasitleÅŸtirilmiÅŸ Regex: "attributeId":"c_brand" ifadesini ve onu takip eden
    # en yakÄ±n "values": [...] yapÄ±sÄ±nÄ± arar. Ä°Ã§ iÃ§e yapÄ±yÄ± (?R) ile deÄŸil,
    # aÃ§gÃ¶zlÃ¼ olmayan .*? ile eÅŸleÅŸtirir.
    pattern = re.compile(r'"attributeId"\s*:\s*"c_brand".*?"values"\s*:\s*(\[.*?\])', re.DOTALL)

    st.write(f"Toplam {len(scripts)} script etiketi bulundu.") # Bilgi

    for i, script in enumerate(scripts):
        script_content = script.get_text()
        if script_content:
            match = pattern.search(script_content)
            if match:
                st.info(f"Script #{i+1} iÃ§inde potansiyel 'c_brand' verisi bulundu.")
                json_like_string = match.group(1)
                # st.text(f"Yakalanan JSON string'i (ilk 150 karakter): {json_like_string[:150]}...")

                # JSON string'ini temizlemeye Ã§alÄ±ÅŸalÄ±m (sondaki virgÃ¼l vb.)
                json_like_string = json_like_string.strip()
                # Nadiren de olsa sonda virgÃ¼l kalabilir
                if json_like_string.endswith(','):
                   json_like_string = json_like_string[:-1]
                   st.warning("JSON string'inin sonundaki fazladan virgÃ¼l temizlendi.")

                try:
                    # JSON olarak ayrÄ±ÅŸtÄ±rmayÄ± dene
                    data_list = json.loads(json_like_string)

                    if isinstance(data_list, list):
                        st.success(f"JSON baÅŸarÄ±yla liste olarak ayrÄ±ÅŸtÄ±rÄ±ldÄ±. {len(data_list)} potansiyel Ã¶ÄŸe bulundu.")
                        processed_count = 0
                        for item in data_list:
                            if isinstance(item, dict) and 'label' in item and 'hitCount' in item:
                                brands_data.append({
                                    fieldnames[0]: item['label'],
                                    fieldnames[1]: item['hitCount']
                                })
                                processed_count += 1
                            # else:
                            #     st.warning(f"Listede beklenen formatta olmayan Ã¶ÄŸe: {item}") # Ã‡ok fazla uyarÄ± verebilir

                        if processed_count > 0:
                           st.success(f"{processed_count} adet marka/Ã¼rÃ¼n sayÄ±sÄ± baÅŸarÄ±yla eklendi.")
                           found_data = True
                           break # Veri bulundu, dÃ¶ngÃ¼den Ã§Ä±k
                        else:
                            st.warning("JSON listesi ayrÄ±ÅŸtÄ±rÄ±ldÄ± ancak iÃ§inde geÃ§erli marka Ã¶ÄŸesi bulunamadÄ±.")
                    else:
                         st.warning(f"Regex eÅŸleÅŸti ancak ayrÄ±ÅŸtÄ±rÄ±lan veri bir liste deÄŸil: {type(data_list)}")

                except json.JSONDecodeError as e:
                    st.warning(f"Script #{i+1} iÃ§inde JSON ayrÄ±ÅŸtÄ±rma hatasÄ±: {e}. Veri baÅŸlangÄ±cÄ±: {json_like_string[:100]}...")
                except Exception as e:
                    st.error(f"Script #{i+1} iÅŸlenirken beklenmedik bir hata: {e}")

    if not found_data or not brands_data:
        st.error("HTML iÃ§inde 'c_brand' attributeId'sine sahip geÃ§erli marka filtresi verisi bulunamadÄ±. LÃ¼tfen HTML dosyasÄ±nÄ±n doÄŸru sayfanÄ±n tam kaynaÄŸÄ± olduÄŸundan ve verinin bir script etiketi iÃ§inde olduÄŸundan emin olun.")
        return None, None

    return brands_data, fieldnames

# --- Streamlit File Uploader ---
uploaded_file = st.file_uploader("HTML DosyasÄ±nÄ± Buraya SÃ¼rÃ¼kleyin veya SeÃ§in", type=["html", "htm"])

if uploaded_file is not None:
    try:
        # DosyayÄ± oku
        stringio = io.StringIO(uploaded_file.getvalue().decode("utf-8"))
        html_content = stringio.read()
        st.success(f"'{uploaded_file.name}' baÅŸarÄ±yla yÃ¼klendi ve okundu.")

        with st.spinner("Marka verileri Ã§Ä±karÄ±lÄ±yor..."):
            brands_data, headers = extract_brands_from_html_content(html_content)

        if brands_data and headers:
            st.success("Marka verileri baÅŸarÄ±yla Ã§Ä±karÄ±ldÄ±!")
            df = pd.DataFrame(brands_data)
            st.dataframe(df, use_container_width=True)
            csv_string = df.to_csv(index=False, encoding='utf-8-sig')
            st.download_button(
               label="CSV Olarak Ä°ndir",
               data=csv_string,
               file_name='sephora_markalar.csv',
               mime='text/csv',
            )
        # else: # Hata mesajÄ± zaten extract_brands_from_html_content iÃ§inde veriliyor
            # pass

    except UnicodeDecodeError:
        st.error("Dosya kodlamasÄ± UTF-8 deÄŸil gibi gÃ¶rÃ¼nÃ¼yor. LÃ¼tfen UTF-8 formatÄ±nda kaydedilmiÅŸ bir HTML dosyasÄ± yÃ¼kleyin.")
    except Exception as e:
        st.error(f"Dosya iÅŸlenirken bir hata oluÅŸtu: {e}")
        st.exception(e) # Daha detaylÄ± hata izi iÃ§in
